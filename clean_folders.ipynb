{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eaf5985",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! conda install  --yes --file TTS.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "3a25a447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\n",
      "Channels:\n",
      " - defaults\n",
      " - conda-forge\n",
      " - pytorch\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "    current version: 24.7.1\n",
      "    latest version: 24.11.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c conda-forge conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /media/michael/Data/anaconda3/envs/TTS\n",
      "\n",
      "  added / updated specs:\n",
      "    - nltk\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  click              pkgs/main/linux-64::click-8.1.7-py311h06a4308_0 \n",
      "  joblib             pkgs/main/linux-64::joblib-1.4.2-py311h06a4308_0 \n",
      "  nltk               pkgs/main/linux-64::nltk-3.9.1-py311h06a4308_0 \n",
      "  regex              pkgs/main/linux-64::regex-2024.9.11-py311h5eee18b_0 \n",
      "  tqdm               pkgs/main/linux-64::tqdm-4.66.5-py311h92b7b1e_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages:\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "! conda install  --yes nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03f47420",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, Latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53108947-10ca-486b-83d4-f9430ee899cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import pandasql as ps\n",
    "# import sklearn \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "import statistics as stat\n",
    "\n",
    "# import plotly.express as px\n",
    "# from plotly.subplots import make_subplots\n",
    "\n",
    "# from ucimlrepo import fetch_ucirepo , dotdict\n",
    "pd.set_option('display.precision', 3)\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d93db42",
   "metadata": {},
   "source": [
    "## Parse Latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defe2731",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylatexenc.latexwalker import LatexWalker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4959f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = LatexWalker(content)\n",
    "\n",
    "(nodelist, pos, len_) = w.get_latex_nodes(pos=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1b28ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "node = nodelist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "665490c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=0, len=23, macroname='documentclass', nodeargd=ParsedMacroArgs(argspec='[{', argnlist=[None, LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=14, len=9, nodelist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=15, len=7, chars='article')], delimiters=('{', '}'))]), macro_post_space='')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55bfcfb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " '__weakref__',\n",
       " '_fields',\n",
       " '_redundant_fields',\n",
       " 'isNodeType',\n",
       " 'latex_verbatim',\n",
       " 'len',\n",
       " 'macro_post_space',\n",
       " 'macroname',\n",
       " 'nodeType',\n",
       " 'nodeargd',\n",
       " 'nodeargs',\n",
       " 'nodeoptarg',\n",
       " 'parsing_state',\n",
       " 'pos']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bfdf045",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LatexMacroNode' object has no attribute 'nodelist'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnodelist\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LatexMacroNode' object has no attribute 'nodelist'"
     ]
    }
   ],
   "source": [
    "len(node.nodelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c437e9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylatexenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca1001f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "316e9f54",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pylatexenc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpylatexenc\u001b[49m\u001b[38;5;241m.\u001b[39mversion\u001b[38;5;241m.\u001b[39mversion_str\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pylatexenc' is not defined"
     ]
    }
   ],
   "source": [
    "pylatexenc.version.version_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c78be1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LatexCommentNode(parsing_state=<parsing state 123169378407952>, pos=4025, len=19, comment=' Affiliation \\\\\\\\', comment_post_space='\\n  '),\n",
       " LatexCommentNode(parsing_state=<parsing state 123169378407952>, pos=4044, len=15, comment=' Address \\\\\\\\', comment_post_space='\\n  '),\n",
       " LatexCommentNode(parsing_state=<parsing state 123169378407952>, pos=4059, len=22, comment=' \\\\texttt{email} \\\\\\\\', comment_post_space='\\n  '),\n",
       " LatexCommentNode(parsing_state=<parsing state 123169378407952>, pos=4081, len=9, comment=' \\\\And', comment_post_space='\\n  '),\n",
       " LatexCommentNode(parsing_state=<parsing state 123169378407952>, pos=4090, len=16, comment=' Coauthor \\\\\\\\', comment_post_space='\\n  '),\n",
       " LatexCommentNode(parsing_state=<parsing state 123169378407952>, pos=4106, len=19, comment=' Affiliation \\\\\\\\', comment_post_space='\\n  '),\n",
       " LatexCommentNode(parsing_state=<parsing state 123169378407952>, pos=4125, len=15, comment=' Address \\\\\\\\', comment_post_space='\\n  '),\n",
       " LatexCommentNode(parsing_state=<parsing state 123169378407952>, pos=4140, len=22, comment=' \\\\texttt{email} \\\\\\\\', comment_post_space='\\n  '),\n",
       " LatexCommentNode(parsing_state=<parsing state 123169378407952>, pos=4162, len=9, comment=' \\\\And', comment_post_space='\\n  '),\n",
       " LatexCommentNode(parsing_state=<parsing state 123169378407952>, pos=4171, len=16, comment=' Coauthor \\\\\\\\', comment_post_space='\\n  '),\n",
       " LatexCommentNode(parsing_state=<parsing state 123169378407952>, pos=4187, len=19, comment=' Affiliation \\\\\\\\', comment_post_space='\\n  '),\n",
       " LatexCommentNode(parsing_state=<parsing state 123169378407952>, pos=4206, len=15, comment=' Address \\\\\\\\', comment_post_space='\\n  '),\n",
       " LatexCommentNode(parsing_state=<parsing state 123169378407952>, pos=4221, len=20, comment=' \\\\texttt{email} \\\\\\\\', comment_post_space='\\n'),\n",
       " LatexCommentNode(parsing_state=<parsing state 123169378407952>, pos=4241, len=2, comment='}', comment_post_space=''),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4243, len=2, chars='\\n\\n'),\n",
       " LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=4245, len=8, macroname='author', nodeargd=ParsedMacroArgs(argspec='{', argnlist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4252, len=1, chars='[')]), macro_post_space=''),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4253, len=4, chars='1,2]'),\n",
       " LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=4257, len=26, nodelist=[LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=4258, len=24, macroname='textbf', nodeargd=ParsedMacroArgs(argspec='{', argnlist=[LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=4265, len=17, nodelist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4266, len=5, chars='Mirco'), LatexSpecialsNode(parsing_state=<parsing state 123169378407952>, pos=4271, len=1, specials_chars='~', nodeargd=None), LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4272, len=9, chars='Ravanelli')], delimiters=('{', '}'))]), macro_post_space='')], delimiters=('{', '}')),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4283, len=1, chars='\\n'),\n",
       " LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=4284, len=8, macroname='author', nodeargd=ParsedMacroArgs(argspec='{', argnlist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4291, len=1, chars='[')]), macro_post_space=''),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4292, len=5, chars='3,16]'),\n",
       " LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=4297, len=28, nodelist=[LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=4298, len=26, macroname='textbf', nodeargd=ParsedMacroArgs(argspec='{', argnlist=[LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=4305, len=19, nodelist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4306, len=7, chars='Titouan'), LatexSpecialsNode(parsing_state=<parsing state 123169378407952>, pos=4313, len=1, specials_chars='~', nodeargd=None), LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4314, len=9, chars='Parcollet')], delimiters=('{', '}'))]), macro_post_space='')], delimiters=('{', '}')),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4325, len=1, chars='\\n'),\n",
       " LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=4326, len=8, macroname='author', nodeargd=ParsedMacroArgs(argspec='{', argnlist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4333, len=1, chars='[')]), macro_post_space=''),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4334, len=2, chars='4]'),\n",
       " LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=4336, len=26, nodelist=[LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=4337, len=24, macroname='textbf', nodeargd=ParsedMacroArgs(argspec='{', argnlist=[LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=4344, len=17, nodelist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4345, len=5, chars='Peter'), LatexSpecialsNode(parsing_state=<parsing state 123169378407952>, pos=4350, len=1, specials_chars='~', nodeargd=None), LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4351, len=9, chars='Plantinga')], delimiters=('{', '}'))]), macro_post_space='')], delimiters=('{', '}')),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4362, len=1, chars='\\n'),\n",
       " LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=4363, len=8, macroname='author', nodeargd=ParsedMacroArgs(argspec='{', argnlist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4370, len=1, chars='[')]), macro_post_space=''),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4371, len=2, chars='5]'),\n",
       " LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=4373, len=20, nodelist=[LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=4374, len=18, macroname='textbf', nodeargd=ParsedMacroArgs(argspec='{', argnlist=[LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=4381, len=11, nodelist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4382, len=3, chars='Aku'), LatexSpecialsNode(parsing_state=<parsing state 123169378407952>, pos=4385, len=1, specials_chars='~', nodeargd=None), LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4386, len=5, chars='Rouhe')], delimiters=('{', '}'))]), macro_post_space='')], delimiters=('{', '}')),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4393, len=1, chars='\\n'),\n",
       " LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=4394, len=8, macroname='author', nodeargd=ParsedMacroArgs(argspec='{', argnlist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4401, len=1, chars='[')]), macro_post_space=''),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4402, len=2, chars='6]'),\n",
       " LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=4404, len=26, nodelist=[LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=4405, len=24, macroname='textbf', nodeargd=ParsedMacroArgs(argspec='{', argnlist=[LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=4412, len=17, nodelist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4413, len=7, chars='Samuele'), LatexSpecialsNode(parsing_state=<parsing state 123169378407952>, pos=4420, len=1, specials_chars='~', nodeargd=None), LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4421, len=7, chars='Cornell')], delimiters=('{', '}'))]), macro_post_space='')], delimiters=('{', '}')),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4430, len=1, chars='\\n'),\n",
       " LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=4431, len=8, macroname='author', nodeargd=ParsedMacroArgs(argspec='{', argnlist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4438, len=1, chars='[')]), macro_post_space=''),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4439, len=4, chars='1,7]'),\n",
       " LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=4443, len=24, nodelist=[LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=4444, len=22, macroname='textbf', nodeargd=ParsedMacroArgs(argspec='{', argnlist=[LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=4451, len=15, nodelist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4452, len=5, chars='Loren'), LatexSpecialsNode(parsing_state=<parsing state 123169378407952>, pos=4457, len=1, specials_chars='~', nodeargd=None), LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4458, len=7, chars='Lugosch')], delimiters=('{', '}'))]), macro_post_space='')], delimiters=('{', '}')),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4467, len=1, chars='\\n'),\n",
       " LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=4468, len=8, macroname='author', nodeargd=ParsedMacroArgs(argspec='{', argnlist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4475, len=1, chars='[')]), macro_post_space=''),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4476, len=2, chars='1]'),\n",
       " LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=4478, len=22, nodelist=[LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=4479, len=20, macroname='textbf', nodeargd=ParsedMacroArgs(argspec='{', argnlist=[LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=4486, len=13, nodelist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4487, len=3, chars='Cem'), LatexSpecialsNode(parsing_state=<parsing state 123169378407952>, pos=4490, len=1, specials_chars='~', nodeargd=None), LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4491, len=7, chars='Subakan')], delimiters=('{', '}'))]), macro_post_space='')], delimiters=('{', '}')),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4500, len=1, chars='\\n'),\n",
       " LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=4501, len=8, macroname='author', nodeargd=ParsedMacroArgs(argspec='{', argnlist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4508, len=1, chars='[')]), macro_post_space=''),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4509, len=2, chars='8]'),\n",
       " LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=4511, len=29, nodelist=[LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=4512, len=27, macroname='textbf', nodeargd=ParsedMacroArgs(argspec='{', argnlist=[LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=4519, len=20, nodelist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4520, len=6, chars='Nauman'), LatexSpecialsNode(parsing_state=<parsing state 123169378407952>, pos=4526, len=1, specials_chars='~', nodeargd=None), LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4527, len=11, chars='Dawalatabad')], delimiters=('{', '}'))]), macro_post_space='')], delimiters=('{', '}')),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4540, len=1, chars='\\n'),\n",
       " LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=4541, len=8, macroname='author', nodeargd=ParsedMacroArgs(argspec='{', argnlist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4548, len=1, chars='[')]), macro_post_space=''),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4549, len=2, chars='9]'),\n",
       " LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=4551, len=26, nodelist=[LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=4552, len=24, macroname='textbf', nodeargd=ParsedMacroArgs(argspec='{', argnlist=[LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=4559, len=17, nodelist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4560, len=10, chars='Abdelwahab'), LatexSpecialsNode(parsing_state=<parsing state 123169378407952>, pos=4570, len=1, specials_chars='~', nodeargd=None), LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4571, len=4, chars='Heba')], delimiters=('{', '}'))]), macro_post_space='')], delimiters=('{', '}')),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4577, len=1, chars='\\n'),\n",
       " LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=4578, len=8, macroname='author', nodeargd=ParsedMacroArgs(argspec='{', argnlist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4585, len=1, chars='[')]), macro_post_space=''),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4586, len=2, chars='1]'),\n",
       " LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=4588, len=25, nodelist=[LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=4589, len=23, macroname='textbf', nodeargd=ParsedMacroArgs(argspec='{', argnlist=[LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=4596, len=16, nodelist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4597, len=8, chars='Jianyuan'), LatexSpecialsNode(parsing_state=<parsing state 123169378407952>, pos=4605, len=1, specials_chars='~', nodeargd=None), LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4606, len=5, chars='Zhong')], delimiters=('{', '}'))]), macro_post_space='')], delimiters=('{', '}')),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4613, len=1, chars='\\n'),\n",
       " LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=4614, len=8, macroname='author', nodeargd=ParsedMacroArgs(argspec='{', argnlist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4621, len=1, chars='[')]), macro_post_space=''),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4622, len=2, chars='10'),\n",
       " LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=4624, len=7, macroname='thanks', nodeargd=ParsedMacroArgs(argspec='', argnlist=[]), macro_post_space=''),\n",
       " LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=4631, len=53, nodelist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4632, len=51, chars='Work conducted while at National Taiwan University.')], delimiters=('{', '}')),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4684, len=1, chars=']'),\n",
       " LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=4685, len=24, nodelist=[LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=4686, len=22, macroname='textbf', nodeargd=ParsedMacroArgs(argspec='{', argnlist=[LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=4693, len=15, nodelist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4694, len=8, chars='Ju-Chieh'), LatexSpecialsNode(parsing_state=<parsing state 123169378407952>, pos=4702, len=1, specials_chars='~', nodeargd=None), LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4703, len=4, chars='Chou')], delimiters=('{', '}'))]), macro_post_space='')], delimiters=('{', '}')),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4709, len=1, chars='\\n'),\n",
       " LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=4710, len=8, macroname='author', nodeargd=ParsedMacroArgs(argspec='{', argnlist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4717, len=1, chars='[')]), macro_post_space=''),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4718, len=4, chars='11*]'),\n",
       " LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=4722, len=23, nodelist=[LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=4723, len=21, macroname='textbf', nodeargd=ParsedMacroArgs(argspec='{', argnlist=[LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=4730, len=14, nodelist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4731, len=8, chars='Sung-Lin'), LatexSpecialsNode(parsing_state=<parsing state 123169378407952>, pos=4739, len=1, specials_chars='~', nodeargd=None), LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4740, len=3, chars='Yeh')], delimiters=('{', '}'))]), macro_post_space='')], delimiters=('{', '}')),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4745, len=1, chars='\\n'),\n",
       " LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=4746, len=8, macroname='author', nodeargd=ParsedMacroArgs(argspec='{', argnlist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4753, len=1, chars='[')]), macro_post_space=''),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4754, len=3, chars='12]'),\n",
       " LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=4757, len=21, nodelist=[LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=4758, len=19, macroname='textbf', nodeargd=ParsedMacroArgs(argspec='{', argnlist=[LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=4765, len=12, nodelist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4766, len=7, chars='Szu-Wei'), LatexSpecialsNode(parsing_state=<parsing state 123169378407952>, pos=4773, len=1, specials_chars='~', nodeargd=None), LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4774, len=2, chars='Fu')], delimiters=('{', '}'))]), macro_post_space='')], delimiters=('{', '}')),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4778, len=1, chars='\\n'),\n",
       " LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=4779, len=8, macroname='author', nodeargd=ParsedMacroArgs(argspec='{', argnlist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4786, len=1, chars='[')]), macro_post_space=''),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4787, len=3, chars='12]'),\n",
       " LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=4790, len=26, nodelist=[LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=4791, len=24, macroname='textbf', nodeargd=ParsedMacroArgs(argspec='{', argnlist=[LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=4798, len=17, nodelist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4799, len=10, chars='Chien-Feng'), LatexSpecialsNode(parsing_state=<parsing state 123169378407952>, pos=4809, len=1, specials_chars='~', nodeargd=None), LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4810, len=4, chars='Liao')], delimiters=('{', '}'))]), macro_post_space='')], delimiters=('{', '}')),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4816, len=1, chars='\\n'),\n",
       " LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=4817, len=8, macroname='author', nodeargd=ParsedMacroArgs(argspec='{', argnlist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4824, len=1, chars='[')]), macro_post_space=''),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4825, len=2, chars='13'),\n",
       " LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=4827, len=7, macroname='thanks', nodeargd=ParsedMacroArgs(argspec='', argnlist=[]), macro_post_space=''),\n",
       " LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=4834, len=70, nodelist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4835, len=68, chars='Work conducted while on an internship at Mila - Quebec AI Institute.')], delimiters=('{', '}')),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4904, len=1, chars=']'),\n",
       " LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=4905, len=28, nodelist=[LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=4906, len=26, macroname='textbf', nodeargd=ParsedMacroArgs(argspec='{', argnlist=[LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=4913, len=19, nodelist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4914, len=5, chars='Elena'), LatexSpecialsNode(parsing_state=<parsing state 123169378407952>, pos=4919, len=1, specials_chars='~', nodeargd=None), LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4920, len=11, chars='Rastorgueva')], delimiters=('{', '}'))]), macro_post_space='')], delimiters=('{', '}')),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4933, len=1, chars='\\n'),\n",
       " LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=4934, len=8, macroname='author', nodeargd=ParsedMacroArgs(argspec='{', argnlist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4941, len=1, chars='[')]), macro_post_space=''),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4942, len=3, chars='14]'),\n",
       " LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=4945, len=27, nodelist=[LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=4946, len=25, macroname='textbf', nodeargd=ParsedMacroArgs(argspec='{', argnlist=[LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=4953, len=18, nodelist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4954, len=8, chars='François'), LatexSpecialsNode(parsing_state=<parsing state 123169378407952>, pos=4962, len=1, specials_chars='~', nodeargd=None), LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4963, len=7, chars='Grondin')], delimiters=('{', '}'))]), macro_post_space='')], delimiters=('{', '}')),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4972, len=1, chars='\\n'),\n",
       " LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=4973, len=8, macroname='author', nodeargd=ParsedMacroArgs(argspec='{', argnlist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4980, len=1, chars='[')]), macro_post_space=''),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4981, len=3, chars='14]'),\n",
       " LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=4984, len=23, nodelist=[LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=4985, len=21, macroname='textbf', nodeargd=ParsedMacroArgs(argspec='{', argnlist=[LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=4992, len=14, nodelist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=4993, len=7, chars='William'), LatexSpecialsNode(parsing_state=<parsing state 123169378407952>, pos=5000, len=1, specials_chars='~', nodeargd=None), LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=5001, len=4, chars='Aris')], delimiters=('{', '}'))]), macro_post_space='')], delimiters=('{', '}')),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=5007, len=1, chars='\\n'),\n",
       " LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=5008, len=8, macroname='author', nodeargd=ParsedMacroArgs(argspec='{', argnlist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=5015, len=1, chars='[')]), macro_post_space=''),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=5016, len=3, chars='15]'),\n",
       " LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=5019, len=21, nodelist=[LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=5020, len=19, macroname='textbf', nodeargd=ParsedMacroArgs(argspec='{', argnlist=[LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=5027, len=12, nodelist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=5028, len=7, chars='Hwidong'), LatexSpecialsNode(parsing_state=<parsing state 123169378407952>, pos=5035, len=1, specials_chars='~', nodeargd=None), LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=5036, len=2, chars='Na')], delimiters=('{', '}'))]), macro_post_space='')], delimiters=('{', '}')),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=5040, len=1, chars='\\n'),\n",
       " LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=5041, len=8, macroname='author', nodeargd=ParsedMacroArgs(argspec='{', argnlist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=5048, len=1, chars='[')]), macro_post_space=''),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=5049, len=3, chars='16]'),\n",
       " LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=5052, len=18, nodelist=[LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=5053, len=16, macroname='textbf', nodeargd=ParsedMacroArgs(argspec='{', argnlist=[LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=5060, len=9, nodelist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=5061, len=3, chars='Yan'), LatexSpecialsNode(parsing_state=<parsing state 123169378407952>, pos=5064, len=1, specials_chars='~', nodeargd=None), LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=5065, len=3, chars='Gao')], delimiters=('{', '}'))]), macro_post_space='')], delimiters=('{', '}')),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=5070, len=1, chars='\\n'),\n",
       " LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=5071, len=8, macroname='author', nodeargd=ParsedMacroArgs(argspec='{', argnlist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=5078, len=1, chars='[')]), macro_post_space=''),\n",
       " LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=5079, len=4, chars='3,7]'),\n",
       " LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=5083, len=25, nodelist=[LatexMacroNode(parsing_state=<parsing state 123169378407952>, pos=5084, len=23, macroname='textbf', nodeargd=ParsedMacroArgs(argspec='{', argnlist=[LatexGroupNode(parsing_state=<parsing state 123169378407952>, pos=5091, len=16, nodelist=[LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=5092, len=6, chars='Renato'), LatexSpecialsNode(parsing_state=<parsing state 123169378407952>, pos=5098, len=1, specials_chars='~', nodeargd=None), LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=5099, len=2, chars='De'), LatexSpecialsNode(parsing_state=<parsing state 123169378407952>, pos=5101, len=1, specials_chars='~', nodeargd=None), LatexCharsNode(parsing_state=<parsing state 123169378407952>, pos=5102, len=4, chars='Mori')], delimiters=('{', '}'))]), macro_post_space='')], delimiters=('{', '}'))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodelist[200:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f3b321",
   "metadata": {},
   "source": [
    "### Configure Latex parser\n",
    "\n",
    "and convert to simple text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82576b8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4654f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpeechBrain: A General-Purpose Speech Toolkit  \n",
      "\n",
      "SpeechBrain is an open-source and all-in-one speech toolkit. It is designed to facilitate the research and development of neural speech processing technologies by being simple, flexible, user-friendly, and well-documented. \n",
      "This paper describes the core architecture designed to support several tasks of common interest, allowing users to naturally conceive, compare and share novel speech processing pipelines.\n",
      "SpeechBrain achieves competitive or state-of-the-art performance in a wide range of speech benchmarks. It also provides training recipes, pretrained models, and inference scripts for popular speech datasets, as well as tutorials which allow anyone with basic Python proficiency to familiarize themselves with speech technologies.  \n",
      "\n",
      "§ INTRODUCTION  \n",
      "\n",
      "Open-source toolkits have played a critical role in the development of speech processing technology .\n",
      "Kaldi , for instance, is an established speech recognition framework, which is impleme\n"
     ]
    }
   ],
   "source": [
    "# shorten segments of multiple newlines to just 2\n",
    "\n",
    "processed = re.sub(r\"\\n{2,}\", r\"  \\n\\n\", processed)\n",
    "\n",
    "print(processed[:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85fc78f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[`][']Hello, world\n",
      "[“][”]Hello, world\n",
      "Hello, world\n",
      "[`][']Hello, world\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(custom_latex_to_text(\n",
    "    r\"\"\"\\begin{inquotes}[`][']Hello, world\\end{inquotes}\"\"\"))\n",
    "# ‘Hello, world’\n",
    "\n",
    "print(custom_latex_to_text(r\"\"\"\\putinquotes[``]['']{Hello, world}\"\"\"))\n",
    "# “Hello, world”\n",
    "\n",
    "print(custom_latex_to_text(r\"\"\"\\putinquotes{Hello, world}\"\"\"))\n",
    "# “Hello, world”\n",
    "\n",
    "print(custom_latex_to_text(r\"\"\"\\putinquotes[`][']{Hello, world}\"\"\"))\n",
    "# ‘Hello, world’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82d2ff22",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = processed[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d00dc36",
   "metadata": {},
   "source": [
    "## Split simple text into chunks \n",
    "for feeding the tacotron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac020dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SpeechBrain: A General-Purpose Speech Toolkit  ',\n",
       " 'SpeechBrain is an open-source and all-in-one speech toolkit',\n",
       " 'It is designed to facilitate the research and development of neural speech processing technologies by being simple, flexible, user-friendly, and well-documented',\n",
       " 'This paper describes the core architecture designed to support several tasks of common interest, allowing users to naturally conceive, compare and share novel speech processing pipelines',\n",
       " 'SpeechBrain achieves competitive or state-of-the-art performance in a wide range of speech benchmarks',\n",
       " 'It also provides training recipes, pretrained models, and inference scripts for popular speech datasets, as well as tutorials which allow anyone with basic Python proficiency to familiarize themselves with speech technologies',\n",
       " '. § INTRODUCTION  ',\n",
       " 'Open-source toolkits have played a critical role in the development of speech processing technology ',\n",
       " 'Kaldi , for instance, is an established speech recognition framework, which is impleme']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def split_text_into_chunks(text, max_length=100):\n",
    "#     chunks = []\n",
    "#     current_chunk = []\n",
    "#     current_length = 0\n",
    "\n",
    "#     for sentence in re.split(r'\\. *\\n?|\\n+', text):  # Split by sentences\n",
    "#         if current_length + len(sentence) <= max_length:\n",
    "#             current_chunk.append(sentence)\n",
    "#             current_length += len(sentence)\n",
    "#         else:\n",
    "#             chunks.append('. '.join(current_chunk) )\n",
    "#             current_chunk = [sentence]\n",
    "#             current_length = len(sentence)\n",
    "    \n",
    "#     if current_chunk:\n",
    "#         chunks.append('. '.join(current_chunk) )\n",
    "\n",
    "#     return chunks\n",
    "\n",
    "# chunks = split_text_into_chunks(test)\n",
    "# chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41d149df",
   "metadata": {},
   "outputs": [],
   "source": [
    "long = chunks[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57bb9c9",
   "metadata": {},
   "source": [
    "\n",
    "breakByCommas(long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8830f8de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It also provides training recipes, pretrained models, ',\n",
       " 'and inference scripts for popular speech datasets, ',\n",
       " 'as well as tutorials which allow anyone with basic Python proficiency to familiarize themselves ',\n",
       " 'with speech technologies']"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "ca209b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It also provides training recipes, pretrained models, and inference scripts for popular speech datasets, as well as tutorials which allow anyone with basic Python proficiency to familiarize themselves with speech technologies'"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9311dfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpeechBrain achieves competitive or state-of-the-art performance in a wide range of speech benchmarks. It also provides training recipes, pretrained models, and inference scripts for popular speech datasets, as well as tutorials which allow anyone with basic Python proficiency to familiarize themselves with speech technologies.      \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['SpeechBrain achieves competitive or state-of-the-art performance in a wide range of speech ',\n",
       " 'benchmarks. ',\n",
       " 'It also provides training recipes, pretrained models, ',\n",
       " 'and inference scripts for popular speech datasets, ',\n",
       " 'as well as tutorials which allow anyone with basic Python proficiency to familiarize themselves ',\n",
       " 'with speech technologies.      . ']"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sent = \"\"\"SpeechBrain achieves competitive or state-of-the-art performance in a wide range of speech benchmarks. It also provides training recipes, pretrained models, and inference scripts for popular speech datasets, as well as tutorials which allow anyone with basic Python proficiency to familiarize themselves with speech technologies.      \"\"\"\n",
    "\n",
    "breakByPeriods(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61c5562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SpeechBrain: A General-Purpose Speech Toolkit', 'SpeechBrain is an open-source and all-in-one speech toolkit. It is designed to facilitate the research and development of neural speech processing technologies by being simple, flexible, user-friendly, and well-documented.', 'This paper describes the core architecture designed to support several tasks of common interest, allowing users to naturally conceive, compare and share novel speech processing pipelines.', 'SpeechBrain achieves competitive or state-of-the-art performance in a wide range of speech benchmarks. It also provides training recipes, pretrained models, and inference scripts for popular speech datasets, as well as tutorials which allow anyone with basic Python proficiency to familiarize themselves with speech technologies.', '§ INTRODUCTION', 'Open-source toolkits have played a critical role in the development of speech processing technology .', 'Kaldi , for instance, is an established speech recognition framework, which is impleme']\n",
      "SpeechBrain is an open-source and all-in-one speech toolkit. It is designed to facilitate the research and development of neural speech processing technologies by being simple, flexible, user-friendly, and well-documented.\n",
      "This paper describes the core architecture designed to support several tasks of common interest, allowing users to naturally conceive, compare and share novel speech processing pipelines.\n",
      "SpeechBrain achieves competitive or state-of-the-art performance in a wide range of speech benchmarks. It also provides training recipes, pretrained models, and inference scripts for popular speech datasets, as well as tutorials which allow anyone with basic Python proficiency to familiarize themselves with speech technologies.\n",
      "Open-source toolkits have played a critical role in the development of speech processing technology .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['SpeechBrain: A General-Purpose Speech Toolkit  \\n\\n',\n",
       " 'SpeechBrain is an open-source and all-in-one speech toolkit. ',\n",
       " 'It is designed to facilitate the research and development of neural speech processing ',\n",
       " 'technologies by being simple, flexible, user-friendly, and well-documented.   \\n\\n',\n",
       " 'This paper describes the core architecture designed to support several tasks of common interest, ',\n",
       " 'allowing users to naturally conceive, compare and share novel speech processing pipelines.   \\n\\n',\n",
       " 'SpeechBrain achieves competitive or state-of-the-art performance in a wide range of speech ',\n",
       " 'benchmarks. ',\n",
       " 'It also provides training recipes, pretrained models, ',\n",
       " 'and inference scripts for popular speech datasets, ',\n",
       " 'as well as tutorials which allow anyone with basic Python proficiency to familiarize themselves ',\n",
       " 'with speech technologies.   \\n\\n',\n",
       " '§ INTRODUCTION  \\n\\n',\n",
       " 'Open-source toolkits have played a critical role in the development of speech processing ',\n",
       " 'technology .   \\n\\n',\n",
       " 'Kaldi , for instance, is an established speech recognition framework, which is impleme  \\n\\n']"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "chunks = breakByParagraphs(test)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd512bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/michael/Data/anaconda3/envs/TTS/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [allow_tf32, disable_jit_profiling]\n",
      "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n"
     ]
    }
   ],
   "source": [
    "from LatexToSpeech import Chunker\n",
    "\n",
    "chunker = Chunker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4e8348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52834b55",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m chunks \u001b[38;5;241m=\u001b[39m chunker\u001b[38;5;241m.\u001b[39msplit_text_into_chunks(\u001b[43mtest\u001b[49m)\n\u001b[1;32m      2\u001b[0m chunks\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "chunks = chunker.split_text_into_chunks(test)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "795151b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5ceb34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "7ee81c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "SpeechBrain: A General-Purpose Speech Toolkit  \n",
       "\n",
       "SpeechBrain is an open-source and all-in-one speech toolkit. It is designed to facilitate the research and development of neural speech processing technologies by being simple, flexible, user-friendly, and well-documented. \n",
       "This paper describes the core architecture designed to support several tasks of common interest, allowing users to naturally conceive, compare and share novel speech processing pipelines.\n",
       "SpeechBrain achieves competitive or state-of-the-art performance in a wide range of speech benchmarks. It also provides training recipes, pretrained models, and inference scripts for popular speech datasets, as well as tutorials which allow anyone with basic Python proficiency to familiarize themselves with speech technologies.  \n",
       "\n",
       "§ INTRODUCTION  \n",
       "\n",
       "Open-source toolkits have played a critical role in the development of speech processing technology .\n",
       "Kaldi , for instance, is an established speech recognition framework, which is impleme"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "7a680794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpeechBrain: A General-Purpose Speech Toolkit  \n",
      "\n",
      "SpeechBrain is an open-source and all-in-one speech toolkit. It is designed to facilitate the research and development of neural speech processing technologies by being simple, flexible, user-friendly, and well-documented.   \n",
      "\n",
      "This paper describes the core architecture designed to support several tasks of common interest, allowing users to naturally conceive, compare and share novel speech processing pipelines.   \n",
      "\n",
      "SpeechBrain achieves competitive or state-of-the-art performance in a wide range of speech benchmarks. It also provides training recipes, pretrained models, and inference scripts for popular speech datasets, as well as tutorials which allow anyone with basic Python proficiency to familiarize themselves with speech technologies.   \n",
      "\n",
      "§ INTRODUCTION  \n",
      "\n",
      "Open-source toolkits have played a critical role in the development of speech processing technology.  \n",
      "\n",
      "Kaldi, for instance, is an established speech recognition framework, which is impleme  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wat = r\"\".join(chunks)\n",
    "print(wat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dfef13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b727ea29",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = re.split(r'(?:\\. +)?\\n+', test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35080f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SpeechBrain: A General-Purpose Speech Toolkit  ',\n",
       " 'SpeechBrain is an open-source and all-in-one speech toolkit. It is designed to facilitate the research and development of neural speech processing technologies by being simple, flexible, user-friendly, and well-documented',\n",
       " 'This paper describes the core architecture designed to support several tasks of common interest, allowing users to naturally conceive, compare and share novel speech processing pipelines.',\n",
       " 'SpeechBrain achieves competitive or state-of-the-art performance in a wide range of speech benchmarks. It also provides training recipes, pretrained models, and inference scripts for popular speech datasets, as well as tutorials which allow anyone with basic Python proficiency to familiarize themselves with speech technologies',\n",
       " '§ INTRODUCTION  ',\n",
       " 'Open-source toolkits have played a critical role in the development of speech processing technology .',\n",
       " 'Kaldi , for instance, is an established speech recognition framework, which is impleme']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2be5e283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It',\n",
       " 'is',\n",
       " 'designed',\n",
       " 'to',\n",
       " 'facilitate',\n",
       " 'the',\n",
       " 'research',\n",
       " 'and',\n",
       " 'development',\n",
       " 'of',\n",
       " 'neural',\n",
       " 'speech',\n",
       " 'processing',\n",
       " 'technologies',\n",
       " 'by',\n",
       " 'being',\n",
       " 'simple']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = \"It is designed to facilitate the research and development of neural speech processing technologies by being simple\"\n",
    "words = x.split(\" \")\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b139904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de955055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1414b26b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 8, 2, 10, 3, 8, 3, 11, 2, 6, 6, 10, 12, 2, 5, 6]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = [len(w) for w in words]\n",
    "lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f03d1718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3934a344",
   "metadata": {},
   "outputs": [],
   "source": [
    "div = math.floor(len(words)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "db7efd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 38\n"
     ]
    }
   ],
   "source": [
    "l = lens[:div]\n",
    "r = lens[div:]\n",
    "print(sum(r),sum(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1b4e30b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "[45] SpeechBrain: A General-Purpose Speech Toolkit\n",
       "\n",
       " ~ \n",
       "\n",
       "[59] SpeechBrain is an open-source and all-in-one speech toolkit\n",
       "\n",
       " ~ \n",
       "\n",
       "[98] It is designed to facilitate the research and development of neural speech processing technologies\n",
       "\n",
       " ~ \n",
       "\n",
       "[61] by being simple, flexible, user-friendly, and well-documented\n",
       "\n",
       " ~ \n",
       "\n",
       "[95] This paper describes the core architecture designed to support several tasks of common interest\n",
       "\n",
       " ~ \n",
       "\n",
       "[90] allowing users to naturally conceive, compare and share novel speech processing pipelines.\n",
       "\n",
       " ~ \n",
       "\n",
       "[90] SpeechBrain achieves competitive or state-of-the-art performance in a wide range of speech\n",
       "\n",
       " ~ \n",
       "\n",
       "[10] benchmarks\n",
       "\n",
       " ~ \n",
       "\n",
       "[52] It also provides training recipes, pretrained models\n",
       "\n",
       " ~ \n",
       "\n",
       "[49] and inference scripts for popular speech datasets\n",
       "\n",
       " ~ \n",
       "\n",
       "[95] as well as tutorials which allow anyone with basic Python proficiency to familiarize themselves\n",
       "\n",
       " ~ \n",
       "\n",
       "[24] with speech technologies\n",
       "\n",
       " ~ \n",
       "\n",
       "[14] § INTRODUCTION\n",
       "\n",
       " ~ \n",
       "\n",
       "[100] Open-source toolkits have played a critical role in the development of speech processing technology.\n",
       "\n",
       " ~ \n",
       "\n",
       "[85] Kaldi, for instance, is an established speech recognition framework, which is impleme"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prev = [f'[{len(w)}] {w}' for w in chunks]\n",
    "display(Markdown(\"\\n\\n ~ \\n\\n\".join(prev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e6a7b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It also provides training recipes',\n",
       " 'pretrained models',\n",
       " 'and inference scripts for popular speech datasets',\n",
       " 'as well as tutorials which allow anyone with basic Python proficiency to familiarize themselves with speech technologies']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long.split(\", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8906a74",
   "metadata": {},
   "source": [
    "## Text to speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a650df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/michael/Data/anaconda3/envs/TTS/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [allow_tf32, disable_jit_profiling]\n",
      "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
      "/tmp/ipykernel_829161/1126089369.py:3: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
      "  from speechbrain.pretrained import Tacotron2, HIFIGAN\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dd999611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.2'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import speechbrain\n",
    "speechbrain.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258bb161",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ord, unord = orderUnorder(chunks)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "1fb7e165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SpeechBrain: A General-Purpose Speech Toolkit  \\n\\n',\n",
       " 'SpeechBrain is an open-source and all-in-one speech toolkit. ',\n",
       " 'It is designed to facilitate the research and development of neural speech processing ',\n",
       " 'technologies by being simple, flexible, user-friendly, and well-documented.   \\n\\n',\n",
       " 'This paper describes the core architecture designed to support several tasks of common interest, ',\n",
       " 'allowing users to naturally conceive, compare and share novel speech processing pipelines.   \\n\\n',\n",
       " 'SpeechBrain achieves competitive or state-of-the-art performance in a wide range of speech ',\n",
       " 'benchmarks. ',\n",
       " 'It also provides training recipes, pretrained models, ',\n",
       " 'and inference scripts for popular speech datasets, ',\n",
       " 'as well as tutorials which allow anyone with basic Python proficiency to familiarize themselves ',\n",
       " 'with speech technologies.   \\n\\n',\n",
       " '§ INTRODUCTION  \\n\\n',\n",
       " 'Open-source toolkits have played a critical role in the development of speech processing technology.  \\n\\n',\n",
       " 'Kaldi, for instance, is an established speech recognition framework, which is impleme  \\n\\n']"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "6d62a129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Open-source toolkits have played a critical role in the development of speech processing technology.  \\n\\n',\n",
       " 'This paper describes the core architecture designed to support several tasks of common interest, ',\n",
       " 'as well as tutorials which allow anyone with basic Python proficiency to familiarize themselves ',\n",
       " 'allowing users to naturally conceive, compare and share novel speech processing pipelines.   \\n\\n',\n",
       " 'SpeechBrain achieves competitive or state-of-the-art performance in a wide range of speech ',\n",
       " 'Kaldi, for instance, is an established speech recognition framework, which is impleme  \\n\\n',\n",
       " 'It is designed to facilitate the research and development of neural speech processing ',\n",
       " 'technologies by being simple, flexible, user-friendly, and well-documented.   \\n\\n',\n",
       " 'SpeechBrain is an open-source and all-in-one speech toolkit. ',\n",
       " 'It also provides training recipes, pretrained models, ',\n",
       " 'and inference scripts for popular speech datasets, ',\n",
       " 'SpeechBrain: A General-Purpose Speech Toolkit  \\n\\n',\n",
       " 'with speech technologies.   \\n\\n',\n",
       " '§ INTRODUCTION  \\n\\n',\n",
       " 'benchmarks. ']"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered = [chunks[i] for i in ord]\n",
    "ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "106f82ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SpeechBrain: A General-Purpose Speech Toolkit  \\n\\n',\n",
       " 'SpeechBrain is an open-source and all-in-one speech toolkit. ',\n",
       " 'It is designed to facilitate the research and development of neural speech processing ',\n",
       " 'technologies by being simple, flexible, user-friendly, and well-documented.   \\n\\n',\n",
       " 'This paper describes the core architecture designed to support several tasks of common interest, ',\n",
       " 'allowing users to naturally conceive, compare and share novel speech processing pipelines.   \\n\\n',\n",
       " 'SpeechBrain achieves competitive or state-of-the-art performance in a wide range of speech ',\n",
       " 'benchmarks. ',\n",
       " 'It also provides training recipes, pretrained models, ',\n",
       " 'and inference scripts for popular speech datasets, ',\n",
       " 'as well as tutorials which allow anyone with basic Python proficiency to familiarize themselves ',\n",
       " 'with speech technologies.   \\n\\n',\n",
       " '§ INTRODUCTION  \\n\\n',\n",
       " 'Open-source toolkits have played a critical role in the development of speech processing technology.  \\n\\n',\n",
       " 'Kaldi, for instance, is an established speech recognition framework, which is impleme  \\n\\n']"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unordered = [ordered[i] for i in unord]\n",
    "unordered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a716c776",
   "metadata": {},
   "source": [
    "### Feed the chunks, recombine and convert to waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa280d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/tts-tacotron2-ljspeech' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/tts-tacotron2-ljspeech' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch model.ckpt: Fetching from HuggingFace Hub 'speechbrain/tts-tacotron2-ljspeech' if not cached\n",
      "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: model\n",
      "/media/michael/Data/anaconda3/envs/TTS/lib/python3.11/site-packages/speechbrain/utils/checkpoints.py:200: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=device)\n",
      "INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/tts-hifigan-ljspeech' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/tts-hifigan-ljspeech' if not cached\n",
      "/media/michael/Data/anaconda3/envs/TTS/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "INFO:speechbrain.utils.fetching:Fetch generator.ckpt: Fetching from HuggingFace Hub 'speechbrain/tts-hifigan-ljspeech' if not cached\n",
      "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: generator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SpeechBrain: A General-Purpose Speech Toolkit', 'SpeechBrain is an open-source and all-in-one speech toolkit. It is designed to facilitate the research and development of neural speech processing technologies by being simple, flexible, user-friendly, and well-documented.', 'This paper describes the core architecture designed to support several tasks of common interest, allowing users to naturally conceive, compare and share novel speech processing pipelines.', 'SpeechBrain achieves competitive or state-of-the-art performance in a wide range of speech benchmarks. It also provides training recipes, pretrained models, and inference scripts for popular speech datasets, as well as tutorials which allow anyone with basic Python proficiency to familiarize themselves with speech technologies.', '§ INTRODUCTION', 'Open-source toolkits have played a critical role in the development of speech processing technology.', 'Kaldi, for instance, is an established speech recognition framework, which is impleme']\n",
      "SpeechBrain is an open-source and all-in-one speech toolkit. It is designed to facilitate the research and development of neural speech processing technologies by being simple, flexible, user-friendly, and well-documented.\n",
      "This paper describes the core architecture designed to support several tasks of common interest, allowing users to naturally conceive, compare and share novel speech processing pipelines.\n",
      "SpeechBrain achieves competitive or state-of-the-art performance in a wide range of speech benchmarks. It also provides training recipes, pretrained models, and inference scripts for popular speech datasets, as well as tutorials which allow anyone with basic Python proficiency to familiarize themselves with speech technologies.\n",
      "run tacotron\n",
      "tensor([514, 513, 512, 513, 488, 507, 403, 522, 385, 322, 290, 305, 147,  78,\n",
      "         73], dtype=torch.int32)\n",
      "run hifigan\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "waveform, order, alignment = text_to_speech(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729114a8",
   "metadata": {},
   "source": [
    "### Save to WAV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0363c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio saved to 27.11.2.wav\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# for chunk in chunks:\n",
    "#     mel_output, mel_length, alignment = tacotron2.encode_text(chunk)\n",
    "#     waveform = hifi_gan.decode_batch(mel_output).squeeze(1)\n",
    "\n",
    "#     if combined_waveform is None:\n",
    "#         combined_waveform = waveform\n",
    "#     else:\n",
    "#         # Align waveforms by padding the shorter one\n",
    "#         #pad_length = max(combined_waveform.size(-1), waveform.size(-1))\n",
    "#         #combined_waveform = torch.nn.functional.pad(combined_waveform, (0, pad_length - combined_waveform.size(-1)))\n",
    "#         #waveform = torch.nn.functional.pad(waveform, (0, pad_length - waveform.size(-1)))\n",
    "#         combined_waveform = torch.cat([combined_waveform, waveform], dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3dc9744f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 13),\n",
       " (1, 2),\n",
       " (2, 4),\n",
       " (3, 10),\n",
       " (4, 5),\n",
       " (5, 6),\n",
       " (6, 14),\n",
       " (7, 3),\n",
       " (8, 1),\n",
       " (9, 8),\n",
       " (10, 9),\n",
       " (11, 0),\n",
       " (12, 11),\n",
       " (13, 12),\n",
       " (14, 7)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unorder = [(i,order[i]) for i in range(len(order))]\n",
    "unorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "12cc8771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11, 8, 1, 7, 2, 4, 5, 14, 9, 10, 3, 12, 13, 0, 6]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unorder = sorted(unorder, key=lambda k: k[1], reverse=False)\n",
    "unorder = [i[0] for i in unorder]\n",
    "unorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "095b033b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(str(torchaudio.list_audio_backends()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "3d5c08f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = split_text_into_chunks(processed[:500], max_length=200)  # Split text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3fa2b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9755ae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev = [f'[{len(w)}] {w}' for w in chunks]\n",
    "display(Markdown(\"\\n\\n ~ \\n\\n\".join(prev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "ca9193ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "SpeechBrain: A General-Purpose Speech Toolkit  \n",
      "\n",
      "SpeechBrain is an open-source and all-in-one speech toolkit.\n",
      " ~ \n",
      "It is designed to facilitate the research and development of neural speech processing technologies by being simple, flexible, user-friendly, and well-documented.\n",
      " ~ \n",
      "\n",
      "This paper describes the core architecture designed to support several tasks of common interest, allowing users to naturally conceive, compare and share novel speech processing pipelines.\n",
      " ~ \n",
      "SpeechBrain achieves competitive or sta.\n"
     ]
    }
   ],
   "source": [
    "print(len(chunks))\n",
    "print(\"\\n ~ \\n\".join(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "6743ed92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 0, 3]"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = chunks\n",
    "\n",
    "list_keys = sorted(range(len(a)), key=lambda k: len(a[k]), reverse=True)\n",
    "\n",
    "list_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "6b3ca7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nThis paper describes the core architecture designed to support several tasks of common interest, allowing users to naturally conceive, compare and share novel speech processing pipelines.',\n",
       " 'It is designed to facilitate the research and development of neural speech processing technologies by being simple, flexible, user-friendly, and well-documented.',\n",
       " 'SpeechBrain: A General-Purpose Speech Toolkit  \\n\\nSpeechBrain is an open-source and all-in-one speech toolkit.',\n",
       " 'SpeechBrain achieves competitive or sta.']"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[a[i] for i in list_keys]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "5f3e6c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SpeechBrain: A General-Purpose Speech Toolkit  \\n\\nSpeechBrain is an open-source and all-in-one speech toolkit.',\n",
       " 'It is designed to facilitate the research and development of neural speech processing technologies by being simple, flexible, user-friendly, and well-documented.',\n",
       " '\\nThis paper describes the core architecture designed to support several tasks of common interest, allowing users to naturally conceive, compare and share novel speech processing pipelines.',\n",
       " 'SpeechBrain achieves competitive or sta.']"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[a[indx] for indx in range(len(list_keys))]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "70937b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['putindblquotes',\n",
       " 'putinquotes',\n",
       " 'mathrm',\n",
       " 'mathbf',\n",
       " 'mathit',\n",
       " 'mathsf',\n",
       " 'mathbb',\n",
       " 'mathtt',\n",
       " 'mathcal',\n",
       " 'mathscr',\n",
       " 'mathfrak',\n",
       " 'input',\n",
       " 'include',\n",
       " 'today',\n",
       " 'texorpdfstring',\n",
       " 'oe',\n",
       " 'OE',\n",
       " 'ae',\n",
       " 'AE',\n",
       " 'aa',\n",
       " 'AA',\n",
       " 'o',\n",
       " 'O',\n",
       " 'ss',\n",
       " 'L',\n",
       " 'l',\n",
       " 'i',\n",
       " 'j',\n",
       " '~',\n",
       " '&',\n",
       " '$',\n",
       " '{',\n",
       " '}',\n",
       " '%',\n",
       " '#',\n",
       " '_',\n",
       " 'textquoteleft',\n",
       " 'textquoteright',\n",
       " 'textquotedblright',\n",
       " 'textquotedblleft',\n",
       " 'textendash',\n",
       " 'textemdash',\n",
       " 'textpm',\n",
       " 'textmp',\n",
       " 'texteuro',\n",
       " 'backslash',\n",
       " 'textbackslash',\n",
       " 'hbar',\n",
       " 'ell',\n",
       " 'forall',\n",
       " 'complement',\n",
       " 'partial',\n",
       " 'exists',\n",
       " 'nexists',\n",
       " 'varnothing',\n",
       " 'emptyset',\n",
       " 'aleph',\n",
       " 'nabla',\n",
       " 'in',\n",
       " 'notin',\n",
       " 'ni',\n",
       " 'prod',\n",
       " 'coprod',\n",
       " 'sum',\n",
       " 'setminus',\n",
       " 'smallsetminus',\n",
       " 'ast',\n",
       " 'circ',\n",
       " 'bullet',\n",
       " 'sqrt',\n",
       " 'propto',\n",
       " 'infty',\n",
       " 'parallel',\n",
       " 'nparallel',\n",
       " 'wedge',\n",
       " 'vee',\n",
       " 'cap',\n",
       " 'cup',\n",
       " 'int',\n",
       " 'iint',\n",
       " 'iiint',\n",
       " 'oint',\n",
       " 'sim',\n",
       " 'backsim',\n",
       " 'simeq',\n",
       " 'approx',\n",
       " 'neq',\n",
       " 'equiv',\n",
       " 'le',\n",
       " 'ge',\n",
       " 'leq',\n",
       " 'geq',\n",
       " 'leqslant',\n",
       " 'geqslant',\n",
       " 'leqq',\n",
       " 'geqq',\n",
       " 'lneqq',\n",
       " 'gneqq',\n",
       " 'll',\n",
       " 'gg',\n",
       " 'nless',\n",
       " 'ngtr',\n",
       " 'nleq',\n",
       " 'ngeq',\n",
       " 'lesssim',\n",
       " 'gtrsim',\n",
       " 'lessgtr',\n",
       " 'gtrless',\n",
       " 'prec',\n",
       " 'succ',\n",
       " 'preceq',\n",
       " 'succeq',\n",
       " 'precsim',\n",
       " 'succsim',\n",
       " 'nprec',\n",
       " 'nsucc',\n",
       " 'subset',\n",
       " 'supset',\n",
       " 'subseteq',\n",
       " 'supseteq',\n",
       " 'nsubseteq',\n",
       " 'nsupseteq',\n",
       " 'subsetneq',\n",
       " 'supsetneq',\n",
       " 'cdot',\n",
       " 'times',\n",
       " 'otimes',\n",
       " 'oplus',\n",
       " 'bigotimes',\n",
       " 'bigoplus',\n",
       " 'cos',\n",
       " 'sin',\n",
       " 'tan',\n",
       " 'arccos',\n",
       " 'arcsin',\n",
       " 'arctan',\n",
       " 'cosh',\n",
       " 'sinh',\n",
       " 'tanh',\n",
       " 'arccosh',\n",
       " 'arcsinh',\n",
       " 'arctanh',\n",
       " 'ln',\n",
       " 'log',\n",
       " 'exp',\n",
       " 'max',\n",
       " 'min',\n",
       " 'sup',\n",
       " 'inf',\n",
       " 'lim',\n",
       " 'limsup',\n",
       " 'liminf',\n",
       " 'prime',\n",
       " 'dag',\n",
       " 'dagger',\n",
       " 'pm',\n",
       " 'mp',\n",
       " ',',\n",
       " ';',\n",
       " ':',\n",
       " ' ',\n",
       " '!',\n",
       " 'quad',\n",
       " 'qquad',\n",
       " 'ldots',\n",
       " 'cdots',\n",
       " 'ddots',\n",
       " 'iddots',\n",
       " 'vdots',\n",
       " 'dots',\n",
       " 'dotsc',\n",
       " 'dotsb',\n",
       " 'dotsm',\n",
       " 'dotsi',\n",
       " 'dotso',\n",
       " 'langle',\n",
       " 'rangle',\n",
       " 'lvert',\n",
       " 'rvert',\n",
       " 'vert',\n",
       " 'lVert',\n",
       " 'rVert',\n",
       " 'Vert',\n",
       " 'mid',\n",
       " 'nmid',\n",
       " 'ket',\n",
       " 'bra',\n",
       " 'braket',\n",
       " 'ketbra',\n",
       " 'uparrow',\n",
       " 'downarrow',\n",
       " 'rightarrow',\n",
       " 'to',\n",
       " 'leftarrow',\n",
       " 'longrightarrow',\n",
       " 'longleftarrow',\n",
       " 'alpha',\n",
       " 'Alpha',\n",
       " 'beta',\n",
       " 'Beta',\n",
       " 'gamma',\n",
       " 'Gamma',\n",
       " 'delta',\n",
       " 'Delta',\n",
       " 'epsilon',\n",
       " 'Epsilon',\n",
       " 'zeta',\n",
       " 'Zeta',\n",
       " 'eta',\n",
       " 'Eta',\n",
       " 'theta',\n",
       " 'Theta',\n",
       " 'iota',\n",
       " 'Iota',\n",
       " 'kappa',\n",
       " 'Kappa',\n",
       " 'lambda',\n",
       " 'Lambda',\n",
       " 'mu',\n",
       " 'Mu',\n",
       " 'nu',\n",
       " 'Nu',\n",
       " 'xi',\n",
       " 'Xi',\n",
       " 'omicron',\n",
       " 'Omicron',\n",
       " 'pi',\n",
       " 'Pi',\n",
       " 'rho',\n",
       " 'Rho',\n",
       " 'sigma',\n",
       " 'Sigma',\n",
       " 'tau',\n",
       " 'Tau',\n",
       " 'upsilon',\n",
       " 'Upsilon',\n",
       " 'phi',\n",
       " 'Phi',\n",
       " 'chi',\n",
       " 'Chi',\n",
       " 'psi',\n",
       " 'Psi',\n",
       " 'omega',\n",
       " 'Omega',\n",
       " 'varepsilon',\n",
       " 'vartheta',\n",
       " 'varpi',\n",
       " 'varrho',\n",
       " 'varsigma',\n",
       " 'varphi',\n",
       " \"'\",\n",
       " '`',\n",
       " '\"',\n",
       " 'c',\n",
       " '^',\n",
       " 'H',\n",
       " 'k',\n",
       " '=',\n",
       " 'b',\n",
       " '.',\n",
       " 'd',\n",
       " 'r',\n",
       " 'u',\n",
       " 'v',\n",
       " 'vec',\n",
       " 'dot',\n",
       " 'hat',\n",
       " 'check',\n",
       " 'breve',\n",
       " 'acute',\n",
       " 'grave',\n",
       " 'tilde',\n",
       " 'bar',\n",
       " 'ddot',\n",
       " 'not',\n",
       " 'emph',\n",
       " 'textrm',\n",
       " 'textit',\n",
       " 'textbf',\n",
       " 'textsc',\n",
       " 'textsl',\n",
       " 'text',\n",
       " 'title',\n",
       " 'author',\n",
       " 'date',\n",
       " 'maketitle',\n",
       " 'url',\n",
       " 'item',\n",
       " 'footnote',\n",
       " 'href',\n",
       " 'part',\n",
       " 'chapter',\n",
       " 'section',\n",
       " 'subsection',\n",
       " 'subsubsection',\n",
       " 'paragraph',\n",
       " 'subparagraph',\n",
       " 'textcolor',\n",
       " 'colorbox',\n",
       " 'fcolorbox',\n",
       " 'hspace',\n",
       " 'vspace',\n",
       " '\\\\',\n",
       " 'frac',\n",
       " 'nicefrac',\n",
       " 'textfrac',\n",
       " 'overline',\n",
       " 'underline',\n",
       " 'widehat',\n",
       " 'widetilde',\n",
       " 'wideparen',\n",
       " 'overleftarrow',\n",
       " 'overrightarrow',\n",
       " 'overleftrightarrow',\n",
       " 'underleftarrow',\n",
       " 'underrightarrow',\n",
       " 'underleftrightarrow',\n",
       " 'overbrace',\n",
       " 'underbrace',\n",
       " 'overgroup',\n",
       " 'undergroup',\n",
       " 'overbracket',\n",
       " 'underbracket',\n",
       " 'overlinesegment',\n",
       " 'underlinesegment',\n",
       " 'overleftharpoon',\n",
       " 'overrightharpoon',\n",
       " 'includegraphics',\n",
       " 'ref',\n",
       " 'autoref',\n",
       " 'cref',\n",
       " 'Cref',\n",
       " 'eqref',\n",
       " 'cite',\n",
       " 'citet',\n",
       " 'citep',\n",
       " 'textasciicircum',\n",
       " 'textasciitilde',\n",
       " 'textexclamdown',\n",
       " 'textcent',\n",
       " 'textsterling',\n",
       " 'textcurrency',\n",
       " 'textyen',\n",
       " 'textbrokenbar',\n",
       " 'textsection',\n",
       " 'textasciidieresis',\n",
       " 'textcopyright',\n",
       " 'textordfeminine',\n",
       " 'guillemotleft',\n",
       " 'textlnot',\n",
       " '-',\n",
       " 'textregistered',\n",
       " 'textasciimacron',\n",
       " 'textdegree',\n",
       " 'texttwosuperior',\n",
       " 'textthreesuperior',\n",
       " 'textasciiacute',\n",
       " 'textmu',\n",
       " 'textparagraph',\n",
       " 'textperiodcentered',\n",
       " 'textonesuperior',\n",
       " 'textordmasculine',\n",
       " 'guillemotright',\n",
       " 'textonequarter',\n",
       " 'textonehalf',\n",
       " 'textthreequarters',\n",
       " 'textquestiondown',\n",
       " 'DH',\n",
       " 'texttimes',\n",
       " 'TH',\n",
       " 'dh',\n",
       " 'textdiv',\n",
       " 'th',\n",
       " 'DJ',\n",
       " 'dj',\n",
       " 'IJ',\n",
       " 'ij',\n",
       " 'NG',\n",
       " 'ng',\n",
       " 'textflorin',\n",
       " 'texthvlig',\n",
       " 'textnrleg',\n",
       " 'textschwa',\n",
       " 'textphi',\n",
       " 'textglotstop',\n",
       " 'textturnk',\n",
       " 'textasciicaron',\n",
       " 'textasciibreve',\n",
       " 'textacutedbl',\n",
       " 'varkappa',\n",
       " 'backepsilon',\n",
       " 'CYRYO',\n",
       " 'CYRDJE',\n",
       " 'CYRIE',\n",
       " 'CYRDZE',\n",
       " 'CYRII',\n",
       " 'CYRYI',\n",
       " 'CYRJE',\n",
       " 'CYRLJE',\n",
       " 'CYRNJE',\n",
       " 'CYRTSHE',\n",
       " 'CYRUSHRT',\n",
       " 'CYRDZHE',\n",
       " 'CYRA',\n",
       " 'CYRB',\n",
       " 'CYRV',\n",
       " 'CYRG',\n",
       " 'CYRD',\n",
       " 'CYRE',\n",
       " 'CYRZH',\n",
       " 'CYRZ',\n",
       " 'CYRI',\n",
       " 'CYRISHRT',\n",
       " 'CYRK',\n",
       " 'CYRL',\n",
       " 'CYRM',\n",
       " 'CYRN',\n",
       " 'CYRO',\n",
       " 'CYRP',\n",
       " 'CYRR',\n",
       " 'CYRS',\n",
       " 'CYRT',\n",
       " 'CYRU',\n",
       " 'CYRF',\n",
       " 'CYRH',\n",
       " 'CYRC',\n",
       " 'CYRCH',\n",
       " 'CYRSH',\n",
       " 'CYRSHCH',\n",
       " 'CYRHRDSN',\n",
       " 'CYRERY',\n",
       " 'CYRSFTSN',\n",
       " 'CYREREV',\n",
       " 'CYRYU',\n",
       " 'CYRYA',\n",
       " 'cyra',\n",
       " 'cyrb',\n",
       " 'cyrv',\n",
       " 'cyrg',\n",
       " 'cyrd',\n",
       " 'cyre',\n",
       " 'cyrzh',\n",
       " 'cyrz',\n",
       " 'cyri',\n",
       " 'cyrishrt',\n",
       " 'cyrk',\n",
       " 'cyrl',\n",
       " 'cyrm',\n",
       " 'cyrn',\n",
       " 'cyro',\n",
       " 'cyrp',\n",
       " 'cyrr',\n",
       " 'cyrs',\n",
       " 'cyrt',\n",
       " 'cyru',\n",
       " 'cyrf',\n",
       " 'cyrh',\n",
       " 'cyrc',\n",
       " 'cyrch',\n",
       " 'cyrsh',\n",
       " 'cyrshch',\n",
       " 'cyrhrdsn',\n",
       " 'cyrery',\n",
       " 'cyrsftsn',\n",
       " 'cyrerev',\n",
       " 'cyryu',\n",
       " 'cyrya',\n",
       " 'cyryo',\n",
       " 'cyrdje',\n",
       " 'cyrie',\n",
       " 'cyrdze',\n",
       " 'cyrii',\n",
       " 'cyryi',\n",
       " 'cyrje',\n",
       " 'cyrlje',\n",
       " 'cyrnje',\n",
       " 'cyrtshe',\n",
       " 'cyrushrt',\n",
       " 'cyrdzhe',\n",
       " 'CYRYAT',\n",
       " 'cyryat',\n",
       " 'CYRBYUS',\n",
       " 'cyrbyus',\n",
       " 'CYRFITA',\n",
       " 'cyrfita',\n",
       " 'CYRIZH',\n",
       " 'cyrizh',\n",
       " 'CYRSEMISFTSN',\n",
       " 'cyrsemisftsn',\n",
       " 'CYRRTICK',\n",
       " 'cyrrtick',\n",
       " 'CYRGUP',\n",
       " 'cyrgup',\n",
       " 'CYRGHCRS',\n",
       " 'cyrghcrs',\n",
       " 'CYRGHK',\n",
       " 'cyrghk',\n",
       " 'CYRZHDSC',\n",
       " 'cyrzhdsc',\n",
       " 'CYRZDSC',\n",
       " 'cyrzdsc',\n",
       " 'CYRKDSC',\n",
       " 'cyrkdsc',\n",
       " 'CYRKVCRS',\n",
       " 'cyrkvcrs',\n",
       " 'CYRKHCRS',\n",
       " 'cyrkhcrs',\n",
       " 'CYRKBEAK',\n",
       " 'cyrkbeak',\n",
       " 'CYRNDSC',\n",
       " 'cyrndsc',\n",
       " 'CYRNG',\n",
       " 'cyrng',\n",
       " 'CYRPHK',\n",
       " 'cyrphk',\n",
       " 'CYRABHHA',\n",
       " 'cyrabhha',\n",
       " 'CYRSDSC',\n",
       " 'cyrsdsc',\n",
       " 'CYRTDSC',\n",
       " 'cyrtdsc',\n",
       " 'CYRY',\n",
       " 'cyry',\n",
       " 'CYRYHCRS',\n",
       " 'cyryhcrs',\n",
       " 'CYRHDSC',\n",
       " 'cyrhdsc',\n",
       " 'CYRTETSE',\n",
       " 'cyrtetse',\n",
       " 'CYRCHRDSC',\n",
       " 'cyrchrdsc',\n",
       " 'CYRCHVCRS',\n",
       " 'cyrchvcrs',\n",
       " 'CYRSHHA',\n",
       " 'cyrshha',\n",
       " 'CYRABHCH',\n",
       " 'cyrabhch',\n",
       " 'CYRABHCHDSC',\n",
       " 'cyrabhchdsc',\n",
       " 'CYRpalochka',\n",
       " 'CYRKHK',\n",
       " 'cyrkhk',\n",
       " 'CYRLDSC',\n",
       " 'cyrldsc',\n",
       " 'CYRNHK',\n",
       " 'cyrnhk',\n",
       " 'CYRCHLDSC',\n",
       " 'cyrchldsc',\n",
       " 'CYRMDSC',\n",
       " 'cyrmdsc',\n",
       " 'CYRAE',\n",
       " 'cyrae',\n",
       " 'CYRSCHWA',\n",
       " 'cyrschwa',\n",
       " 'CYRABHDZE',\n",
       " 'cyrabhdze',\n",
       " 'CYROTLD',\n",
       " 'cyrotld',\n",
       " 'CYRGDSC',\n",
       " 'cyrgdsc',\n",
       " 'CYRGDSCHCRS',\n",
       " 'cyrgdschcrs',\n",
       " 'CYRHHK',\n",
       " 'cyrhhk',\n",
       " 'CYRHHCRS',\n",
       " 'cyrhhcrs',\n",
       " 'textbaht',\n",
       " 'enskip',\n",
       " 'textcompwordmark',\n",
       " 'quotesinglbase',\n",
       " 'quotedblbase',\n",
       " 'textdagger',\n",
       " 'textdaggerdbl',\n",
       " 'textbullet',\n",
       " 'textellipsis',\n",
       " 'textperthousand',\n",
       " 'textpertenthousand',\n",
       " 'backprime',\n",
       " 'guilsinglleft',\n",
       " 'guilsinglright',\n",
       " 'textreferencemark',\n",
       " 'textinterrobang',\n",
       " 'textfractionsolidus',\n",
       " 'textasteriskcentered',\n",
       " 'textdiscount',\n",
       " 'nolinebreak',\n",
       " 'textcolonmonetary',\n",
       " 'textlira',\n",
       " 'textnaira',\n",
       " 'textwon',\n",
       " 'textdong',\n",
       " 'textpeso',\n",
       " 'textcelsius',\n",
       " 'textnumero',\n",
       " 'textcircledP',\n",
       " 'wp',\n",
       " 'textrecipe',\n",
       " 'textservicemark',\n",
       " 'texttrademark',\n",
       " 'textohm',\n",
       " 'textmho',\n",
       " 'textestimated',\n",
       " 'beth',\n",
       " 'gimel',\n",
       " 'daleth',\n",
       " 'textleftarrow',\n",
       " 'textuparrow',\n",
       " 'textrightarrow',\n",
       " 'textdownarrow',\n",
       " 'leftrightarrow',\n",
       " 'updownarrow',\n",
       " 'nwarrow',\n",
       " 'nearrow',\n",
       " 'searrow',\n",
       " 'swarrow',\n",
       " 'nleftarrow',\n",
       " 'nrightarrow',\n",
       " 'arrowwaveleft',\n",
       " 'arrowwaveright',\n",
       " 'twoheadleftarrow',\n",
       " 'twoheadrightarrow',\n",
       " 'leftarrowtail',\n",
       " 'rightarrowtail',\n",
       " 'mapsto',\n",
       " 'hookleftarrow',\n",
       " 'hookrightarrow',\n",
       " 'looparrowleft',\n",
       " 'looparrowright',\n",
       " 'leftrightsquigarrow',\n",
       " 'nleftrightarrow',\n",
       " 'Lsh',\n",
       " 'Rsh',\n",
       " 'curvearrowleft',\n",
       " 'curvearrowright',\n",
       " 'circlearrowleft',\n",
       " 'circlearrowright',\n",
       " 'leftharpoonup',\n",
       " 'leftharpoondown',\n",
       " 'upharpoonright',\n",
       " 'upharpoonleft',\n",
       " 'rightharpoonup',\n",
       " 'rightharpoondown',\n",
       " 'downharpoonright',\n",
       " 'downharpoonleft',\n",
       " 'rightleftarrows',\n",
       " 'dblarrowupdown',\n",
       " 'leftrightarrows',\n",
       " 'leftleftarrows',\n",
       " 'upuparrows',\n",
       " 'rightrightarrows',\n",
       " 'downdownarrows',\n",
       " 'leftrightharpoons',\n",
       " 'rightleftharpoons',\n",
       " 'nLeftarrow',\n",
       " 'nLeftrightarrow',\n",
       " 'nRightarrow',\n",
       " 'Leftarrow',\n",
       " 'Uparrow',\n",
       " 'Rightarrow',\n",
       " 'Downarrow',\n",
       " 'Leftrightarrow',\n",
       " 'Updownarrow',\n",
       " 'Lleftarrow',\n",
       " 'Rrightarrow',\n",
       " 'rightsquigarrow',\n",
       " 'DownArrowUpArrow',\n",
       " 'blacksquare',\n",
       " 'dotplus',\n",
       " 'rightangle',\n",
       " 'angle',\n",
       " 'measuredangle',\n",
       " 'sphericalangle',\n",
       " 'surfintegral',\n",
       " 'volintegral',\n",
       " 'clwintegral',\n",
       " 'therefore',\n",
       " 'because',\n",
       " 'homothetic',\n",
       " 'lazysinv',\n",
       " 'wr',\n",
       " 'cong',\n",
       " 'approxnotequal',\n",
       " 'approxeq',\n",
       " 'tildetrpl',\n",
       " 'allequal',\n",
       " 'asymp',\n",
       " 'Bumpeq',\n",
       " 'bumpeq',\n",
       " 'doteq',\n",
       " 'doteqdot',\n",
       " 'fallingdotseq',\n",
       " 'risingdotseq',\n",
       " 'eqcirc',\n",
       " 'circeq',\n",
       " 'estimates',\n",
       " 'starequal',\n",
       " 'triangleq',\n",
       " 'between',\n",
       " 'notlessgreater',\n",
       " 'notgreaterless',\n",
       " 'uplus',\n",
       " 'sqsubset',\n",
       " 'sqsupset',\n",
       " 'sqsubseteq',\n",
       " 'sqsupseteq',\n",
       " 'sqcap',\n",
       " 'sqcup',\n",
       " 'ominus',\n",
       " 'oslash',\n",
       " 'odot',\n",
       " 'circledcirc',\n",
       " 'circledast',\n",
       " 'circleddash',\n",
       " 'boxplus',\n",
       " 'boxminus',\n",
       " 'boxtimes',\n",
       " 'boxdot',\n",
       " 'vdash',\n",
       " 'dashv',\n",
       " 'top',\n",
       " 'perp',\n",
       " 'truestate',\n",
       " 'forcesextra',\n",
       " 'Vdash',\n",
       " 'Vvdash',\n",
       " 'VDash',\n",
       " 'nvdash',\n",
       " 'nvDash',\n",
       " 'nVdash',\n",
       " 'nVDash',\n",
       " 'vartriangleleft',\n",
       " 'vartriangleright',\n",
       " 'trianglelefteq',\n",
       " 'trianglerighteq',\n",
       " 'original',\n",
       " 'image',\n",
       " 'multimap',\n",
       " 'hermitconjmatrix',\n",
       " 'intercal',\n",
       " 'veebar',\n",
       " 'rightanglearc',\n",
       " 'bigwedge',\n",
       " 'bigvee',\n",
       " 'bigcap',\n",
       " 'bigcup',\n",
       " 'diamond',\n",
       " 'star',\n",
       " 'divideontimes',\n",
       " 'bowtie',\n",
       " 'ltimes',\n",
       " 'rtimes',\n",
       " 'leftthreetimes',\n",
       " 'rightthreetimes',\n",
       " 'backsimeq',\n",
       " 'curlyvee',\n",
       " 'curlywedge',\n",
       " 'Subset',\n",
       " 'Supset',\n",
       " 'Cap',\n",
       " 'Cup',\n",
       " 'pitchfork',\n",
       " 'lessdot',\n",
       " 'gtrdot',\n",
       " 'verymuchless',\n",
       " 'verymuchgreater',\n",
       " 'lesseqgtr',\n",
       " 'gtreqless',\n",
       " 'curlyeqprec',\n",
       " 'curlyeqsucc',\n",
       " 'lnsim',\n",
       " 'gnsim',\n",
       " 'precedesnotsimilar',\n",
       " 'succnsim',\n",
       " 'ntriangleleft',\n",
       " 'ntriangleright',\n",
       " 'ntrianglelefteq',\n",
       " 'ntrianglerighteq',\n",
       " 'vdots',\n",
       " 'udots',\n",
       " 'barwedge',\n",
       " 'varperspcorrespond',\n",
       " 'lceil',\n",
       " 'rceil',\n",
       " 'lfloor',\n",
       " 'rfloor',\n",
       " 'recorder',\n",
       " 'ulcorner',\n",
       " 'urcorner',\n",
       " 'llcorner',\n",
       " 'lrcorner',\n",
       " 'frown',\n",
       " 'smile',\n",
       " 'lmoustache',\n",
       " 'rmoustache',\n",
       " 'textlangle',\n",
       " 'textrangle',\n",
       " 'textblank',\n",
       " 'textvisiblespace',\n",
       " 'square',\n",
       " 'bigtriangleup',\n",
       " 'blacktriangle',\n",
       " 'vartriangle',\n",
       " 'blacktriangleright',\n",
       " 'triangleright',\n",
       " 'bigtriangledown',\n",
       " 'blacktriangledown',\n",
       " 'triangledown',\n",
       " 'blacktriangleleft',\n",
       " 'triangleleft',\n",
       " 'lozenge',\n",
       " 'bigcirc',\n",
       " 'textopenbullet',\n",
       " 'textbigcircle',\n",
       " 'textmusicalnote',\n",
       " 'quarternote',\n",
       " 'flat',\n",
       " 'natural',\n",
       " 'sharp',\n",
       " 'longleftrightarrow',\n",
       " 'Longleftarrow',\n",
       " 'Longrightarrow',\n",
       " 'Longleftrightarrow',\n",
       " 'longmapsto',\n",
       " 'blacklozenge',\n",
       " 'clockoint',\n",
       " 'sqrint',\n",
       " 'amalg',\n",
       " 'lessapprox',\n",
       " 'gtrapprox',\n",
       " 'lneq',\n",
       " 'gneq',\n",
       " 'lnapprox',\n",
       " 'gnapprox',\n",
       " 'lesseqqgtr',\n",
       " 'gtreqqless',\n",
       " 'eqslantless',\n",
       " 'eqslantgtr',\n",
       " 'precneqq',\n",
       " 'succneqq',\n",
       " 'precapprox',\n",
       " 'succapprox',\n",
       " 'precnapprox',\n",
       " 'succnapprox',\n",
       " 'subseteqq',\n",
       " 'supseteqq',\n",
       " 'subsetneqq',\n",
       " 'supsetneqq',\n",
       " 'textdollar',\n",
       " 'textquotesingle',\n",
       " 'textasciigrave',\n",
       " 'lbrace',\n",
       " 'rbrace',\n",
       " 'lnot',\n",
       " 'div',\n",
       " 'eth',\n",
       " 'textdoublepipe',\n",
       " 'texttildelow',\n",
       " 'texttheta',\n",
       " 'textvartheta',\n",
       " 'Stigma',\n",
       " 'Digamma',\n",
       " 'digamma',\n",
       " 'Koppa',\n",
       " 'Sampi',\n",
       " 'textTheta',\n",
       " 'dddot',\n",
       " 'ddddot',\n",
       " 'hslash',\n",
       " 'mho',\n",
       " 'surd',\n",
       " 'Colon',\n",
       " 'lessequivlnt',\n",
       " 'greaterequivlnt',\n",
       " 'preccurlyeq',\n",
       " 'succcurlyeq',\n",
       " 'upslopeellipsis',\n",
       " 'downslopeellipsis',\n",
       " 'circledS',\n",
       " 'diagup',\n",
       " 'rightmoon',\n",
       " 'mercury',\n",
       " 'venus',\n",
       " 'male',\n",
       " 'jupiter',\n",
       " 'saturn',\n",
       " 'uranus',\n",
       " 'neptune',\n",
       " 'pluto',\n",
       " 'aries',\n",
       " 'taurus',\n",
       " 'gemini',\n",
       " 'cancer',\n",
       " 'leo',\n",
       " 'virgo',\n",
       " 'libra',\n",
       " 'scorpio',\n",
       " 'sagittarius',\n",
       " 'capricornus',\n",
       " 'aquarius',\n",
       " 'pisces',\n",
       " 'eighthnote',\n",
       " 'UpArrowBar',\n",
       " 'DownArrowBar',\n",
       " 'LeftRightVector',\n",
       " 'RightUpDownVector',\n",
       " 'DownLeftRightVector',\n",
       " 'LeftUpDownVector',\n",
       " 'LeftVectorBar',\n",
       " 'RightVectorBar',\n",
       " 'RightUpVectorBar',\n",
       " 'RightDownVectorBar',\n",
       " 'DownLeftVectorBar',\n",
       " 'DownRightVectorBar',\n",
       " 'LeftUpVectorBar',\n",
       " 'LeftDownVectorBar',\n",
       " 'LeftTeeVector',\n",
       " 'RightTeeVector',\n",
       " 'RightUpTeeVector',\n",
       " 'RightDownTeeVector',\n",
       " 'DownLeftTeeVector',\n",
       " 'DownRightTeeVector',\n",
       " 'LeftUpTeeVector',\n",
       " 'LeftDownTeeVector',\n",
       " 'UpEquilibrium',\n",
       " 'ReverseUpEquilibrium',\n",
       " 'RoundImplies',\n",
       " 'Angle',\n",
       " 'LeftTriangleBar',\n",
       " 'RightTriangleBar',\n",
       " 'RuleDelayed',\n",
       " 'perspcorrespond',\n",
       " 'Equal',\n",
       " 'NestedLessLess',\n",
       " 'NestedGreaterGreater',\n",
       " 'openbracketleft',\n",
       " 'openbracketright',\n",
       " 'exercise',\n",
       " 'uebung',\n",
       " 'hint',\n",
       " 'hints',\n",
       " 'hinweis',\n",
       " 'hinweise',\n",
       " 'id',\n",
       " 'Ident']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specs = [env.macroname for env in l2t_context_db.iter_macro_specs()]\n",
    "specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd04d4dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "15f519ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<pylatexenc.latex2text.MacroTextSpec object at 0x7ff1d97e03d0>, None, None)\n"
     ]
    }
   ],
   "source": [
    "wat = \"author\"\n",
    "spec = l2t_context_db.get_macro_spec(wat), l2t_context_db.get_environment_spec(wat), l2t_context_db.get_specials_spec(wat) \n",
    "macro, env, special = spec\n",
    "print(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7a992b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "11a1b6da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'discard',\n",
       " 'macroname',\n",
       " 'simplify_repl']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eb11d918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True author <function <lambda> at 0x7ff1d97b2840>\n"
     ]
    }
   ],
   "source": [
    "print(macro.discard, macro.macroname, macro.simplify_repl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f6c4b16d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__annotations__',\n",
       " '__builtins__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__closure__',\n",
       " '__code__',\n",
       " '__defaults__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__get__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__globals__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__kwdefaults__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__name__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__qualname__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " dir(macro.simplify_repl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f5e3a8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mmacro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplify_repl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2tobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
      "\u001b[0;31mSource:\u001b[0m   \n",
      "        \u001b[0;34m(\u001b[0m\u001b[0;34m'author'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2tobj\u001b[0m\u001b[0;34m:\u001b[0m \\\n",
      "         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml2tobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_doc_author'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2tobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodelist_to_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodeargd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margnlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m      /media/michael/Data/anaconda3/envs/TTS/lib/python3.11/site-packages/pylatexenc/latex2text/_defaultspecs.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "??macro.simplify_repl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "726adb87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function pylatexenc.latex2text._defaultspecs.<lambda>(n, l2tobj)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec.simplify_repl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6746270",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b191f036-5a99-4c05-bf92-0d0e06348648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44326941-fdbf-4465-adb0-006a6d883c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join , isdir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TTS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
