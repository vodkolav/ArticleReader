{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3817f393-5aa0-4395-b4d7-32aebfce613f",
   "metadata": {},
   "source": [
    "# Big Data Project: Transforming Scientific Articles into Videos with Speech using Apache Spark and Kafka\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c3735a-37f8-4aa4-8853-5fe628b0bb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make modules from py files auto-reload when changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13692290-f4df-474f-b861-095623f1f808",
   "metadata": {},
   "source": [
    "# TTS \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "598aff3b",
   "metadata": {},
   "source": [
    "## Basic run just for test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b60c2a-8c99-418f-b8e2-4969640da1bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3012adb6-6d2c-49a4-8e04-eda485d271dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datetime import datetime\n",
    "from ArticleReader.Chunker import Chunker\n",
    "from ArticleReader.LatexToSpeech import LatexParser\n",
    "from ArticleReader.Narrator import Narrator\n",
    "from Benchmarking import Bench\n",
    "import pandas as pd \n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2b1a90-97c5-42c5-be11-08cc4fdb709f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"data/arXiv-2106.04624v1/main.tex\"\n",
    "output_file = \"output/\" + datetime.now().strftime(r\"%y.%m.%d-%H\")\n",
    "\n",
    "parser = LatexParser()\n",
    "content = parser.read_latex(input_file)\n",
    "processed = parser.custom_latex_to_text(content)\n",
    "parser.save_text(processed, \"dbg/spec_my.txt\")\n",
    "\n",
    "tables = parser.get_tables()\n",
    "parser.save_text(tables, \"dbg/tables.tex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8688131-5656-4c4a-9525-75634809aaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker = Chunker(max_len=200)\n",
    "chunker.split_text_into_chunks(processed)\n",
    "chunks = chunker.get_test_batch(10, 0)\n",
    "# chunks = chunker.chunks\n",
    "chunker.save_chunks_as_text(output_file + \".md\", chunks)\n",
    "print(\"text chunks:\", [len(ch) for ch in chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c389ecf-b341-411b-8536-4fb88408cad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "narrator = Narrator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e331ac-983c-4ca3-969d-dc07a29cd30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# break\n",
    "# waveforms, durations = narrator.text_to_speech_batched(chunks)\n",
    "# durations_sec = durations / 22050.0\n",
    "\n",
    "# print(\"durations: \", durations_sec)\n",
    "\n",
    "# waveform = torch.cat(waveforms, dim=1)\n",
    "\n",
    "# print(\"saving audio\")\n",
    "# narrator.save_audio(output_file + \".wav\", waveform)\n",
    "\n",
    "# narrator.save_video(output_file)\n",
    "\n",
    "# narrator.generate_srt(chunks, durations_sec, output_file + \".srt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbada7f-a7cb-4aa9-b37f-514adea931ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "11fc7827-03fa-43b0-9c6e-42a7a8b1e8c0",
   "metadata": {},
   "source": [
    "## Run batch from sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976dc433-1c04-489c-b331-a3a5b188dde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_from_sorted = chunker.get_batch_sorted(batch_size=100, start=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5b5761-982a-4361-98f1-cf71d1da8463",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_from_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7f5cd9-f3d2-4180-9ddf-d0d8ebcf653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_converted = narrator.text_to_speech_df(batch_from_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62284bb-4b49-43ea-a141-ae216713ef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_converted.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d40af90-28da-4d34-b347-0da54d3ea9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58d3601-00e0-4803-8250-a4152b9f9bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore order of sentences\n",
    "batch_converted.sort_values(\"index\", ascending=True, inplace=True)\n",
    "# recombine and save sound\n",
    "waveform = torch.cat(tuple(batch_converted.waveform), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69381811-e6bc-4d63-9616-2150719b7566",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"saving batch\")\n",
    "narrator.save_audio(output_file + \".wav\", waveform)\n",
    "chunker.save_chunks_as_text(output_file + \".md\", batch_converted.sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eb0715-f418-4377-86db-8dc56b8d8294",
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(s) for s in batch_converted.sentence]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "481240b2-9584-40b1-924e-9f4f7b0a665b",
   "metadata": {},
   "source": [
    "## TTS benchmarking\n",
    "Benchmarking batch sizes - how they impact memory utilization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93ccbc4c-8a42-4485-9ef7-ab5cc6160108",
   "metadata": {},
   "source": [
    "#### Experiment report v.1  \n",
    "schema of the json file   \n",
    "```\n",
    "variables: \n",
    "    device(CPU/GPU) \n",
    "    tts_model (tacotron, fastspeech,...)\n",
    "    vocoder_model (hifigan, ...)\n",
    "    batch_size (1,2,3, 5, 10, 20, 30, 50, 70, 100, 200)\n",
    "    chunk_length (50 : 50 : 500)\n",
    "parameters: \n",
    "    time \n",
    "    experiment_id \n",
    "    chunk_duration \n",
    "    avg_percent_silence     \n",
    "    tts_model:\n",
    "        model_id (name)\n",
    "        max_memory_use \n",
    "        run_time \n",
    "        memory_log []\n",
    "        exceptions \n",
    "        n_threads?\n",
    "    vocoder_model:\n",
    "        model_id (name)\n",
    "        max_memory_use \n",
    "        run_time \n",
    "        memory_log []\n",
    "        exceptions \n",
    "        n_threads?\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ff99115-2830-4215-9d5d-6df6331b8750",
   "metadata": {},
   "source": [
    "#### Experiment report v.2 \n",
    "schema of the json file   \n",
    "```\n",
    "\n",
    "    #variables: \n",
    "device(CPU/GPU) \n",
    "tts_model (tacotron, fastspeech,...)\n",
    "vocoder_model (hifigan, ...)\n",
    "batch_size (1,2,3, 5, 10, 20, 30, 50, 70, 100, 200)\n",
    "chunk_length (50 : 50 : 500)\n",
    "\n",
    "    #parameters: \n",
    "time \n",
    "experiment_id\n",
    "stage: (tts/vocoder)\n",
    "chunk_durations \n",
    "avg_percent_silence\n",
    "max_memory_use \n",
    "run_time \n",
    "memory_log []\n",
    "exceptions \n",
    "n_threads?\n",
    "\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c0c3e27e-c5cf-46d1-8b52-01bf25369b2e",
   "metadata": {},
   "source": [
    "### Gather benchmark data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c7a29d-fe62-4e6a-aa77-84b8ab5ad682",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bench = Bench()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a82c6d-3478-4aa2-ac56-3a6aa2520aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "case = {\"chunk_length\": 50, # (50 : 50 : 500)\n",
    "     \"batch_size\": 2, # (1, 2, 3, 5, 10, 20, 30, 50, 70, 100, 200)        \n",
    "     \"tts_model\": \"tts-tacotron2-ljspeech\",\n",
    "     \"vocoder_model\": \"tts-hifigan-ljspeech\",\n",
    "     \"device\": \"CPU\", \n",
    "       }\n",
    "case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7989f2-a161-4e7b-b9d0-c8bcdf796200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_run = bench.run_experiment(processed, case)\n",
    "# with open(\"benchmark/\" + experiment_run[0][\"experiment_id\"] + \".json\", \"w+\") as f:\n",
    "#     json.dump(experiment_run,f)\n",
    "# print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b610891-f075-4a78-a019-fd72f69aceaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiment_run"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b375b54c-7d99-4074-b928-a7df23a12240",
   "metadata": {},
   "source": [
    "## Multiple experiments run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebd4edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datetime import datetime\n",
    "from ArticleReader.Chunker import Chunker\n",
    "from ArticleReader.LatexToSpeech import LatexParser\n",
    "from ArticleReader.Narrator import Narrator\n",
    "from Benchmarking import Bench\n",
    "import pandas as pd \n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aabe87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"data/arXiv-2106.04624v1/main.tex\"\n",
    "output_file = \"output/\" + datetime.now().strftime(r\"%y.%m.%d-%H\")\n",
    "\n",
    "parser = LatexParser()\n",
    "content = parser.read_latex(input_file)\n",
    "processed = parser.custom_latex_to_text(content)\n",
    "parser.save_text(processed, \"dbg/spec_my.txt\")\n",
    " \n",
    "tables = parser.get_tables()\n",
    "parser.save_text(tables, \"dbg/tables.tex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993a0c6b-4177-4c44-bed6-a610a310fdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "smallgrid = {\"chunk_length\": [75,100],\n",
    "             \"batch_size\": (2, 3),\n",
    "             \"tts_model\": [\"tts-tacotron2-ljspeech\"],\n",
    "             \"vocoder_model\": [\"tts-hifigan-ljspeech\"],\n",
    "             \"device\": [\"CPU\"], \n",
    "       }\n",
    "smallgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e2a5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bench = Bench()\n",
    "bench.run_experiments(processed, smallgrid, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae0a36d-6e07-42a3-ba98-b3323aa372fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "largegrid = {\"chunk_length\": [1000],\n",
    "             \"batch_size\": (100, 2),\n",
    "             \"tts_model\": [\"tts-tacotron2-ljspeech\"],\n",
    "             \"vocoder_model\": [\"tts-hifigan-ljspeech\"],\n",
    "             \"device\": [\"CPU\"],\n",
    "            }\n",
    "largegrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0297de9-0ac2-498b-94b2-734f253d85de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bench = Bench()\n",
    "bench.run_experiments(processed, largegrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a193e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "1270546432 /  1.074e+9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb9a821",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullgrid = {\"chunk_length\": list(range(50, 1500, 135)),\n",
    "             \"batch_size\": (1, 3, 5, 10, 20, 50, 70, 100, 125, 150, 200, 300),\n",
    "             \"tts_model\": [\"tts-tacotron2-ljspeech\", ],\n",
    "             \"vocoder_model\": [\"tts-hifigan-ljspeech\"],\n",
    "             \"device\": [\"CPU\"], \n",
    "       }\n",
    "fullgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51681149",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"grid sizes:\")\n",
    "print(\"-\"*20)\n",
    "cases = 1\n",
    "for k,v in fullgrid.items():\n",
    "    cases = cases*len(v)\n",
    "    print(k, \":\", len(v))\n",
    "print(\"-\"*20)\n",
    "print(\"total cases: \", cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8884d8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bench = Bench()\n",
    "bench.run_experiments(processed, fullgrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180c75ce-2872-4635-a8c1-2833cb8267b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = bench.permutations(grid)\n",
    "\n",
    "with open(\"cases.json\", 'w+') as f:\n",
    "    json.dump(cases, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4dca33",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnch_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73b159f-c64a-4c68-b7f4-73b3a47e92dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(experiment_run[\"parameters\"][\"tts_model\"][\"memory_log\"][\"time\"][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e57f9bd2-1e74-413a-bb8b-0f8acc67080f",
   "metadata": {},
   "source": [
    "### Examine individual memory logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3c33c2-e47d-4019-8fc0-0de37f9439ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = pd.DataFrame(narrator.profilers['vocoder'].memory_log,)\n",
    "log['time'] = pd.to_datetime(log[0], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2446c9-2850-4fdf-9858-20eed7feeeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "log.plot(x='time', y=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71acb162-003d-405a-a56e-df58ed630168",
   "metadata": {},
   "outputs": [],
   "source": [
    "log.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90554e69-8616-4428-bc5a-5f14c83bf3a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdd56b5-5b6b-4ad7-85b2-0009dca84be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.torch_version.internal_version"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb961f1b-f728-4a4d-892d-febb6cf381c4",
   "metadata": {},
   "source": [
    "# Trash"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a77ea7d3-802a-4f1f-a61f-2d9a385ecbff",
   "metadata": {},
   "source": [
    "## GPU benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71068fc-88c9-47ff-a449-f63495e6c4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#import torchvision.models as models\n",
    "from torchaudio.pipelines import Tacotron2TTSBundle \n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc493e2b-6844-4f32-80f0-222537f0ea5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = models.hubert_base()\n",
    "# inputs = torch.randn(5, 224)\n",
    "\n",
    "# with profile(activities=[ProfilerActivity.CPU],\n",
    "#         profile_memory=True, record_shapes=True) as prof:\n",
    "#     model(inputs)\n",
    "\n",
    "# print(prof.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823cbe02-4045-4032-8afe-c49bd342f06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttcp = narrator.profiles['tacotron']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b702069-aca6-43e6-8e22-b4030f497d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = ttcp.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=20)\n",
    "tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497850d3-2987-44f1-a7bc-3bfaa6995302",
   "metadata": {},
   "outputs": [],
   "source": [
    "eve = ttcp.events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29b5f9e-57cd-4dc4-8a30-4feacdf083ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "eve1000 = eve[1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b132439-dc79-463b-aadb-88e45cea29a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(eve1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2a6c0a-2389-4282-a5ef-35b1630424f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eve1000.time_range.start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43600d8-0ac2-40f3-8904-d67b7d86e475",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(eve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacd5b7e-e9ac-408f-8eda-00679969c08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eve1000.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123584b7-4070-4543-8705-5fc598a6258a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ka = ttcp.key_averages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2167eab-75b7-4aa9-87f9-16afd667dba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ka)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbd7a8e-6754-4844-a767-115146a0de8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ka)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef040e8-a99c-4f5d-b265-0c89cbe56225",
   "metadata": {},
   "outputs": [],
   "source": [
    "ka0 = ka[0]\n",
    "ka0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2d5d4a-19aa-449b-ade5-858a255363d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(ka0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3c7d37-428b-4333-9fb7-01825b54cc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ka0.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadd1918-ae41-4ff8-b110-e822d3e5326f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttcp.export_memory_timeline.__dir__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab5bf41-fd59-476b-9584-1f94210db461",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ttcp.export_memory_timeline.__self__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbd6258-7e1c-4532-8661-856eefe81cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttcp.export_memory_timeline(\"CPU_tacotron.raw.json.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d393d2c9-8f11-4842-865f-ff9c15b4350e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vcdp = narrator.profiles['vocoder']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68a62e4-513f-4c04-8669-4ef3c51e616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vcdp.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44d9e29d-342a-416e-963b-d20ef8983cfc",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyspark_TTS]",
   "language": "python",
   "name": "conda-env-pyspark_TTS-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
